# FBGO-MLP-RGaussian
Full Batch Gradient Optimization on Multilayer Perceptron structure with RGaussian Activation (FBGO-MLP-RGaussian).
## Key Features
-  Full Batch Gradient Optimization with a single output layer and arbitrary number of hidden layers and nodes, utilizing R-Gaussian and Sigmoid Activation Functions on the Standard CIFAR Dataset:
  - Rgauss_cifar.py
  - Sigmoid_cifar.py
-  Batch Normalization with full batch processing, a single output layer, and arbitrary number of hidden layers and nodes utilizing ReLU activation  on the standard CIFAR dataset:
   - BN_ReLu_cifar.py
-  Dataset Description & Availability
  - Details of the datasets used and **Kaggle links** are provided in Dataset_README.md
-  Standard Normalization of CIFAR Dataset
  - normalization_std_cifar.py 
    
