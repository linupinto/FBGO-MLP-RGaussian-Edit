# A brief Over view of the programme BN_ReLu_cifar.py

## Key features
- âœ… Implements Batch Normalization with full batch processing
- âœ… Input normalization at each node using moving average and variance
- âœ… Full Gradient Optimization method is considered
- âœ… Two hidden layer and a single output layer
- âœ… ReLu activation in each node of the hidden layer
- âœ… Linear activation in the output layer
- âœ… Uses standard normalized CIFAR data

### Manin highlight
- ðŸš€Thsis can be extented to any number of hidden layers and nodes.
