# A brief Over view of the programme BN_ReLu_cifar.py

## Key features
- âœ… Implements Batch Normalization with full batch processing
- âœ… Input normalization at each node using moving average and variance
- âœ… Full Gradient Optimization method is considered
- âœ… For experimental analysis two hidden layer and a single output layer is structured in the code.
    - The code  will work on any number of hidden layes and hidden nodes.
- âœ… ReLu activation in each node of the hidden layer
- âœ… Linear activation in the output layer
- âœ… Uses standard normalized CIFAR data

### Main highlight
- ðŸš€The code is implemented for any number of hidden layers and nodes.
